#Imports
import seaborn as sns
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random


#Ver.s
print("Tensorflow: ", tf.__version__, " Seaborn: ", sns.__version__)

#Load
mnist = tf.keras.datasets.mnist

#Create dataframe
from tensorflow.keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

'''#Show number of examples
sns.countplot(x=y_train)

#Show plot of ^
plt.show()'''


#Check to make sure train X is all numbs
print("Any NAN Training: ", np.isnan(x_train).any())

#Check to make sure test X is all numbs
print("Any NAN Testing: ", np.isnan(x_test).any())

#Tell model what shape to expect
input_shape = (32,32,3)

#Reshape data
#x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)

#Normalize data to
x_train = x_train.astype('float32') / 255.0

#Same 4 test
x_test = x_test.astype('float32') / 255.0

#Convert labels to be onehot, not sparse
y_train = tf.one_hot(y_train.astype(np.int32), depth = 10)
y_test = tf.one_hot(y_test.astype(np.int32), depth=10)

#Show an example from MNIST
'''plt.imshow(x_train[random.randint(0, 59999)][:,:,0], cmap='gray')
plt.show()'''

#
batch_size = 128
num_classes = 10
epochs = 5

#Build the model (Dear god...)
model = tf.keras.models.Sequential(
    [
        tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu', input_shape=input_shape),
        tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=input_shape),
        tf.keras.layers.MaxPool2D(),
        tf.keras.layers.Dropout(0.25),
        tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=input_shape),
        tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=input_shape),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ]
)


model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train,epochs=10,validation_data=(x_test, y_test))

fig, ax = plt.subplots(2,1)
ax[0].set_title("Loss")
ax[0].set_xlabel("Epochs")
ax[0].set_ylabel("Loss")

ax[1].plot(history.history['acc'], color = 'b', label="Training Accuracy")
ax[1].plot(history.history['val_acc'], color = 'r', label="Testing Accuracy")
legend=ax[1].legend(loc='best', shadow=True)
ax[1].set_title("Accuracy")
ax[1].set_xlabel("Epochs")
ax[1].set_ylabel("Accuracy")

plt.tight_layout()
plt.show()